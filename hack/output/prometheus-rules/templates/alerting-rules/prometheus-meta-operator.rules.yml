---
# Source: prometheus-rules/templates/alerting-rules/prometheus-meta-operator.rules.yml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    app.kubernetes.io/name: "prometheus-rules"
    app.kubernetes.io/instance: "RELEASE-NAME"
    app.giantswarm.io/branch: "[[ -Branch ]]"
    app.giantswarm.io/commit: "[[ .SHA ]]"
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/version: "[[ .AppVersion ]]"
    helm.sh/chart: "prometheus-rules-2.1.1"
    giantswarm.io/service-type: managed
  name: prometheus-meta-operator
  namespace: monitoring
spec:
  groups:
  - name: observability
    rules:
    - alert: "Heartbeat"
      expr: up{app="prometheus",instance!="prometheus-agent"}
      for: 10m
      labels:
        area: "empowerment"
        installation: 
        team: "atlas"
        topic: "observability"
        type: "heartbeat"
        namespace: "monitoring" # Needed due to https://github.com/prometheus-operator/prometheus-operator/issues/3737
      annotations:
        description: This alert is used to ensure the entire alerting pipeline is functional.
    - alert: "MatchingNumberOfPrometheusAndCluster"
      annotations:
        description: This alert is used to ensure we have as many workload cluster prometheus as we have workload cluster CR.
        opsrecipe: matching-number-of-prometheus-and-cluster/
      # This expression list all the cluster IDs that exist and are not being deleted and compares them (using unless) to the running prometheus pods.
      # If a prometheus is missing, this alert will fire. This alert will not check if a prometheus is running when it should not (e.g. deleted cluster)
      expr: |
        (
          sum by(cluster_id) (
            {__name__=~"cluster_service_cluster_info|cluster_operator_cluster_status", status!="Deleting"}
          ) unless sum by(cluster_id) (
            label_replace(
              kube_pod_container_status_running{container="prometheus", namespace!="-prometheus", namespace=~".*-prometheus"},
              "cluster_id", "$2", "pod", "(prometheus-)(.+)(-.+)"
            )
          )
        ) + (
          sum by (cluster_name) (
            capi_cluster_status_phase{phase!="Deleting"}
          ) unless sum by (cluster_name) (
            label_replace(kube_pod_container_status_running{container="prometheus",namespace=~".*-prometheus"}, 
            "cluster_name", "$2", "pod", "(prometheus-)(.+)(-.+)"
            )
          )
        )
        > 0
      for: 10m
      labels:
        area: "empowerment"
        cancel_if_mc_kube_state_metrics_down: "true"
        cancel_if_cluster_status_creating: "true"
        cancel_if_outside_working_hours: "false"
        installation: 
        severity: "page"
        team: "atlas"
        topic: "observability"
    - alert: "PrometheusMetaOperatorReconcileErrors"
      annotations:
        description: 'prometheus-meta-operator controller {{ $labels.controller }} too many reconcile errors.'
        opsrecipe: "pmo-reconcile-errors/"
      expr: |
        avg_over_time(operatorkit_controller_errors_total{app="prometheus-meta-operator"}[20m]) > 0
      for: 1h
      labels:
        area: "empowerment"
        cancel_if_mc_kube_state_metrics_down: "false"
        cancel_if_cluster_status_creating: "true"
        cancel_if_outside_working_hours: "true"
        installation: 
        severity: "page"
        team: "atlas"
        topic: "observability"
