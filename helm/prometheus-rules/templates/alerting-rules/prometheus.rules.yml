apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  creationTimestamp: null
  labels:
    {{- include "labels.common" . | nindent 4 }}
  name: prometheus.rules
  namespace: {{ .Values.namespace  }}
spec:
  groups:
  - name: prometheus
    rules:
    - alert: PrometheusAvailabilityRatio
      annotations:
        description: '{{`Prometheus {{$labels.pod}} has availability ratio of {{ printf "%.2f" $value }} (min 0.8) over the last hour.`}}'
        opsrecipe: prometheus-resource-limit-reached/
        dashboard: promavailability/prometheus-availability
      expr: avg(avg_over_time(kube_pod_status_ready{namespace=~"(.*)-prometheus", condition="true", cluster_type="management_cluster"}[1h])) by (pod) < 0.8
      # At startup, availability starts at 0 for a few minutes. So ratio grows slowly from 0.
      for: 30m
      labels:
        area: empowerment
        cancel_if_any_apiserver_down: "true"
        cancel_if_cluster_status_creating: "true"
        cancel_if_cluster_status_updating: "true"
        cancel_if_cluster_status_deleting: "true"
        cancel_if_cluster_has_no_workers: "true"
        cancel_if_outside_working_hours: "true"
        severity: page
        team: atlas
        topic: observability
    - alert: PrometheusCantCommunicateWithKubernetesAPI
      annotations:
        description: '{{`Prometheus can''t communicate with Kubernetes API.`}}'
        opsrecipe: prometheus-cant-communicate/
      expr: rate(prometheus_sd_kubernetes_http_request_total{app!="promxy-app", status_code="<error>"}[15m]) > 0.25
      for: 30m
      labels:
        area: empowerment
        cancel_if_any_apiserver_down: "true"
        cancel_if_cluster_status_creating: "true"
        cancel_if_cluster_status_updating: "true"
        cancel_if_cluster_status_deleting: "true"
        cancel_if_cluster_has_no_workers: "true"
        cancel_if_outside_working_hours: "false"
        severity: page
        team: atlas
        topic: observability
    ## Pages Atlas when prometheus fails to send samples to cortex
    - alert: PrometheusMissingGrafanaCloud
      annotations:
        description: 'Prometheus is not sending data to Grafana Cloud.'
        opsrecipe: tbd/
      expr: absent(prometheus_remote_storage_samples_total{remote_name="grafana-cloud"})
      for: 1h
      labels:
        area: empowerment
        cancel_if_outside_working_hours: "true"
        severity: page
        team: atlas
        topic: observability
    - alert: PrometheusFailsToCommunicateWithRemoteStorageAPI
      annotations:
        description: '{{`Prometheus can''t communicate with Remote Storage API at {{ $labels.url }}.`}}'
        opsrecipe: prometheus-cant-communicate-with-remote-storage-api/
        dashboard: promRW001/prometheus-remote-write
      expr: rate(prometheus_remote_storage_samples_failed_total[10m]) > 0.1 or rate(prometheus_remote_storage_samples_total[10m]) == 0 or rate(prometheus_remote_storage_metadata_retried_total[10m]) > 0
      for: 1h
      labels:
        area: empowerment
        cancel_if_outside_working_hours: "true"
        severity: page
        team: atlas
        topic: observability
    - alert: PrometheusRuleFailures
      annotations:
        description: {{`Prometheus {{$labels.installation}}/{{$labels.cluster_id}} has failed to evaluate rule(s) {{ printf "%.2f" $value }} time(s).`}}
        summary: Prometheus is failing rule evaluations.
        opsrecipe: prometheus-rule-failures/
      expr: rate(prometheus_rule_evaluation_failures_total[30m]) > 0
      for: 1h
      labels:
        area: empowerment
        severity: page
        team: atlas
        topic: observability
        cancel_if_outside_working_hours: "true"
    - alert: PrometheusJobScrapingFailure
      annotations:
        description: {{`Prometheus {{$labels.installation}}/{{$labels.cluster_id}} has failed to scrape all targets in {{$labels.job}} job.`}}
        summary: Prometheus fails to scrape all targets in a job.
        opsrecipe: prometheus-job-scraping-failure/
      expr: (count(up == 0) BY (job, installation, cluster_id) / count(up) BY (job, installation, cluster_id)) == 1
      for: 1d
      labels:
        area: empowerment
        severity: none
        team: atlas
        topic: observability
        cancel_if_outside_working_hours: "true"
{{- if ne .Values.managementCluster.provider.kind "kvm" }}
    - alert: PrometheusCriticalJobScrapingFailure
      annotations:
        description: {{`Prometheus {{$labels.installation}}/{{$labels.cluster_id}} has failed to scrape all targets in {{$labels.job}} job.`}}
        summary: Prometheus fails to scrape all targets in a job.
        opsrecipe: prometheus-job-scraping-failure/
      ## We ignore bastion hosts node exporters
      expr: |-
        (
          count(
            up{
              app=~"kubernetes|kube-controller-manager|kube-scheduler|kubelet|node-exporter|kube-state-metrics",
              job!~".*bastions.*"
            } == 0
          ) BY (app,job, installation, cluster_id)
          /
          count(
            up{
              app=~"kubernetes|kube-controller-manager|kube-scheduler|kubelet|node-exporter|kube-state-metrics",
              job!~".*bastions.*"
            }
          ) BY (app, job, installation, cluster_id)
        ) == 1
      for: 3d
      labels:
        area: empowerment
        severity: page
        team: atlas
        topic: observability
        cancel_if_outside_working_hours: "true"
        cancel_if_cluster_is_not_running_prometheus_agent: "true"
        cancel_if_cluster_status_creating: "true"
        cancel_if_cluster_status_deleting: "true"
{{- end }}
