apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  creationTimestamp: null
  labels:
    {{- include "labels.common" . | nindent 4 }}
  name: prometheus.rules
  namespace: {{ .Values.namespace  }}
spec:
  groups:
  - name: prometheus
    rules:
    - alert: PrometheusCantCommunicateWithKubernetesAPI
      annotations:
        description: '{{`Prometheus can''t communicate with Kubernetes API.`}}'
        opsrecipe: prometheus-cant-communicate/
      expr: rate(prometheus_sd_kubernetes_http_request_total{app!="promxy-app", status_code="<error>"}[15m]) > 0.25
      for: 30m
      labels:
        area: empowerment
        cancel_if_any_apiserver_down: "true"
        cancel_if_cluster_status_creating: "true"
        cancel_if_cluster_status_updating: "true"
        cancel_if_cluster_status_deleting: "true"
        cancel_if_outside_working_hours: {{ include "workingHoursOnly" . }}
        severity: page
        team: atlas
        topic: observability
    ## Pages Atlas when prometheus fails to send samples to cortex
    - alert: PrometheusFailsToCommunicateWithRemoteStorageAPI
      annotations:
        description: '{{`Prometheus can''t communicate with Remote Storage API at {{ $labels.url }}.`}}'
        opsrecipe: prometheus-cant-communicate-with-remote-storage-api/
      expr: rate(prometheus_remote_storage_samples_failed_total{instance!="prometheus-agent"}[1h]) > 0.1 or rate(prometheus_remote_storage_samples_total{instance!="prometheus-agent"}[1h]) == 0 or rate(prometheus_remote_storage_metadata_retried_total{instance!="prometheus-agent"}[5m]) > 0
      for: 1h
      labels:
        area: empowerment
        cancel_if_outside_working_hours: "true"
        severity: page
        team: atlas
        topic: observability
    - alert: PrometheusRuleFailures
      annotations:
        description: {{`Prometheus {{$labels.installation}}/{{$labels.cluster_id}} has failed to evaluate rule(s) {{ printf "%.2f" $value }} time(s).`}}
        summary: Prometheus is failing rule evaluations.
        opsrecipe: prometheus-rule-failures/
      expr: rate(prometheus_rule_evaluation_failures_total[30m]) > 0
      for: 1h
      labels:
        area: empowerment
        severity: page
        team: atlas
        topic: observability
        cancel_if_outside_working_hours: "true"
    - alert: PrometheusJobScrapingFailure
      annotations:
        description: {{`Prometheus {{$labels.installation}}/{{$labels.cluster_id}} has failed to scrape all targets in {{$labels.job}} job.`}}
        summary: Prometheus fails to scrape all targets in a job.
        opsrecipe: prometheus-job-scraping-failure/
      expr: (count(up == 0) BY (job, installation, cluster_id) / count(up) BY (job, installation, cluster_id)) == 1
      for: 1d
      labels:
        area: empowerment
        severity: notify
        team: atlas
        topic: observability
        cancel_if_outside_working_hours: "true"

    - alert: PrometheusCriticalJobScrapingFailure
      annotations:
        description: {{`Prometheus {{$labels.installation}}/{{$labels.cluster_id}} has failed to scrape all targets in {{$labels.job}} job.`}}
        summary: Prometheus fails to scrape all targets in a job.
        opsrecipe: prometheus-job-scraping-failure/
      expr: (count(up{app=~"kubernetes|kube-controller-manager|kube-scheduler|kubelet|node-exporter|kube-state-metrics"} == 0) BY (app,job, installation, cluster_id) / count(up{app=~"kubernetes|kube-controller-manager|kube-scheduler|kubelet|node-exporter|kube-state-metrics"}) BY (app, job, installation, cluster_id)) == 1
      for: 3d
      labels:
        area: empowerment
        severity: page
        team: atlas
        topic: observability
        cancel_if_outside_working_hours: "true"
        cancel_if_cluster_status_creating: true
        cancel_if_cluster_status_deleting: true
