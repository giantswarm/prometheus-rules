apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  creationTimestamp: null
  labels:
    {{- include "labels.common" . | nindent 4 }}
  name: node-exporter.rules
  namespace: {{ .Values.namespace  }}
spec:
  groups:
  - name: node-exporter
    rules:
    - alert: NodeExporterCollectorFailed
      annotations:
        description: '{{`NodeExporter Collector {{ $labels.collector }} on {{ $labels.instance }} is failed.`}}'
        runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/node-exporter-device-error/
        # TODO(@giantswarm/team-atlas): the namespace filter should be removed when this completed https://github.com/giantswarm/roadmap/issues/3791, see https://github.com/giantswarm/prometheus-rules/pull/1491
      expr: node_scrape_collector_success{collector!~"conntrack|bonding|hwmon|powersupplyclass|mdadm|nfs|nfsd|tapestats|fibrechannel|nvme|watchdog", namespace="kube-system"} == 0
      for: 5m
      labels:
        area: kaas
        cancel_if_outside_working_hours: "true"
        severity: page
        team: tenet
        topic: observability
  - name: resource-usage
    rules:
    # IncorrectResourceUsageData alert detects if the data used in the Grafana Cloud Resource Usage dashboard is incorrect by comparing the dashboard data against data from the kubelet.
    - alert: IncorrectResourceUsageData
      annotations:
        description: '{{`Data used in the Grafana Cloud Resource Usage dashboard is incorrect for cluster {{ $labels.cluster_id }}.`}}'
        runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/resource-usage-dashboard/
      expr: |
        quantile_over_time(0.9, aggregation:node:cpu_cores_total[120m:30m])  / on(cluster_id, cluster_type, customer, installation, pipeline, provider, region)  quantile_over_time(0.9, (sum(machine_cpu_cores)by(cluster_id, cluster_type, customer, installation, pipeline, provider, region))[120m:30m]) < 0.9
        or
        quantile_over_time(0.9, aggregation:node:memory_memtotal_bytes_total[120m:30m])  / on(cluster_id, cluster_type, customer, installation, pipeline, provider, region)  quantile_over_time(0.9, (sum(machine_memory_bytes)by(cluster_id, cluster_type, customer, installation, pipeline, provider, region))[120m:30m]) < 0.9
      for: 1h
      labels:
        area: kaas
        cancel_if_outside_working_hours: "true"
        severity: page
        team: tenet
        topic: observability
