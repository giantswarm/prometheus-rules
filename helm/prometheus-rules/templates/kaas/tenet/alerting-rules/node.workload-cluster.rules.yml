apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  creationTimestamp: null
  labels:
    {{- include "labels.common" . | nindent 4 }}
  name: node.workload-cluster.rules
  namespace: {{ .Values.namespace  }}
spec:
  groups:
  - name: node
    rules:
    - alert: WorkloadClusterNodeIsUnschedulable
      annotations:
        description: '{{`Node {{ $labels.node }} in cluster {{ $labels.installation }}/{{ $labels.cluster_id }} is unschedulable.`}}'
        runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/node-is-unschedulable/
      expr: kube_node_spec_unschedulable != 0
      for: 45m
      labels:
        area: kaas
        cancel_if_outside_working_hours: {{ include "workingHoursOnly" . }}
        severity: notify
        team: {{ include "providerTeam" . }}
        topic: kubernetes
    - alert: WorkloadClusterControlPlaneNodeMissing
      annotations:
        description: '{{`Control plane node in cluster {{ $labels.installation }}/{{ $labels.cluster_id }} is missing.`}}'
        runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/master-node-missing/
      expr: count by (cluster_id, installation, pipeline, provider) (kubernetes_build_info{app="kubelet"} unless on (node) kube_node_role{role!~"control-plane|master"}) == 0
      for: 30m
      labels:
        area: kaas
        control_plane_node_down: "true"
        severity: page
        team: {{ include "providerTeam" . }}
        topic: kubernetes
    - alert: WorkloadClusterHAControlPlaneDownForTooLong
      annotations:
        description: '{{`Control plane node in HA cluster {{ $labels.installation }}/{{ $labels.cluster_id }} is down for a long time.`}}'
        runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/master-node-missing/
      expr: sum by (cluster_id, installation, pipeline, provider) (kubernetes_build_info{app="kubelet"} * on (cluster_id, node) group_left kube_node_role{role="control-plane"}) == 2 or sum by (cluster_id, installation, pipeline, provider) (kubernetes_build_info{app="kubelet"} * on (cluster_id, node) group_left kube_node_role{role="master"}) == 2
      for: 30m
      labels:
        area: kaas
        cancel_if_outside_working_hours: "true"
        control_plane_node_down: "true"
        severity: page
        team: {{ include "providerTeam" . }}
        topic: kubernetes
    - alert: NodeStateFlappingUnderLoad
      # Check if the kubelet status is flapping, unless the node is under load.
      # It helps to read this rule from the bottom upwards.
      #
      # If the kubelet status is flapping between Ready and something else,
      # matching against the kubelet labels, as kube_node_status_condition labels
      # by the node name, and node_exporter labels by the node name,
      # unless,
      # the load over 15 minutes divided by number of CPUs is higher than 2 (the node is overloaded).
      annotations:
        description: '{{`Node {{ $labels.node }} status is flapping under load in cluster {{ $labels.installation }}/{{ $labels.cluster_id }}.`}}'
      expr: |
        (
          sum(node_load15{cluster_type="workload_cluster"})
            by (cluster_id, installation, node, pipeline, provider)
          / count(rate(node_cpu_seconds_total{cluster_type="workload_cluster", mode="idle"}[5m]))
            by (cluster_id, installation, node, pipeline, provider)
        ) >= 2
        unless on (cluster_id, installation, node, pipeline, provider) (
          kube_node_labels{cluster_type="workload_cluster"}
          and on (cluster_id, installation, node, pipeline, provider)
          changes(kube_node_status_condition{cluster_type="workload_cluster", condition="Ready", status="true"}[30m])
        ) >= 6
      for: 10m
      labels:
        area: kaas
        cancel_if_outside_working_hours: {{ include "workingHoursOnly" . }}
        severity: notify
        team: {{ include "providerTeam" . }}
        topic: kubernetes
    - alert: NodeHasConstantOOMKills
      # Check if a core component is restarted because memory reasons
      # in the last hour.
      annotations:
        description: '{{`Node {{ $labels.ip }} in cluster {{ $labels.installation }}/{{ $labels.cluster_id }} has constant OOM kills.`}}'
      expr: kube_pod_container_status_restarts_total{cluster_type="workload_cluster", namespace=~"(giantswarm|kube-system)"} - kube_pod_container_status_restarts_total{cluster_type="workload_cluster"} offset 1h >= 1 AND ignoring(reason) kube_pod_container_status_last_terminated_reason{cluster_type="workload_cluster", reason="OOMKilled"} > 0
      for: 10m
      labels:
        area: kaas
        cancel_if_outside_working_hours: {{ include "workingHoursOnly" . }}
        severity: notify
        team: {{ include "providerTeam" . }}
        topic: kubernetes
    - alert: NodeConnTrackAlmostExhausted
      annotations:
        description: '{{`Node {{ $labels.node }} in cluster {{ $labels.installation }}/{{ $labels.cluster_id }} reports a connection usage above 85% for the last 15 minutes.`}}'
        runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/node-conntrack-limits/
      expr: node_nf_conntrack_entries{cluster_type="workload_cluster"} / node_nf_conntrack_entries_limit{cluster_type="workload_cluster"} >= 0.85
      for: 15m
      labels:
        area: kaas
        cancel_if_outside_working_hours: {{ include "workingHoursOnly" . }}
        severity: page
        team: {{ include "providerTeam" . }}
        topic: kubernetes
    - alert: MachineEntropyTooLow
      annotations:
        description: '{{`Machine {{ $labels.instance }} in cluster {{ $labels.installation }}/{{ $labels.cluster_id }} entropy is too low.`}}'
        runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/low-entropy/
      expr: node_entropy_available_bits{cluster_type="workload_cluster"} < 250
      for: 10m
      labels:
        area: kaas
        cancel_if_outside_working_hours: {{ include "workingHoursOnly" . }}
        severity: notify
        team: {{ include "providerTeam" . }}
        topic: infrastructure
    - alert: MachineAllocatedFileDescriptorsTooHigh
      annotations:
        description: '{{`Machine {{ $labels.instance }} in cluster {{ $labels.installation }}/{{ $labels.cluster_id }} has too many allocated file descriptors.`}}'
        runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/high-number-file-descriptors/
      expr: node_filefd_allocated{cluster_type="workload_cluster"} / node_filefd_maximum{cluster_type="workload_cluster"} * 100 > 80
      for: 15m
      labels:
        area: kaas
        cancel_if_outside_working_hours: {{ include "workingHoursOnly" . }}
        severity: notify
        team: {{ include "providerTeam" . }}
        topic: infrastructure
    - alert: WorkloadClusterMasterMemoryUsageTooHigh
      annotations:
        description: '{{`Machine {{ $labels.instance }} in cluster {{ $labels.installation }}/{{ $labels.cluster_id }} memory usage is too high (less than 10% and 2G of allocatable memory).`}}'
        runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/master-machine-usage-too-high/
      expr: |-
        ( ( (
              ( node_memory_MemTotal_bytes{cluster_type="workload_cluster"}
              - node_memory_MemFree_bytes{cluster_type="workload_cluster"}
              - node_memory_Cached_bytes{cluster_type="workload_cluster"}
              )
              / (node_memory_MemTotal_bytes{cluster_type="workload_cluster"}
            ) * 100
          )
        ) > 80
        and
        ( node_memory_MemFree_bytes{cluster_type="workload_cluster"}
          + node_memory_Cached_bytes{cluster_type="workload_cluster"}
        ) < 2147483648)
        and on (cluster_id, node) kube_node_role{cluster_type="workload_cluster", role=~"control-plane|master"}
      for: 60m
      labels:
        area: kaas
        cancel_if_outside_working_hours: "true"
        severity: page
        team: se
        topic: infrastructure
    - alert: providerTeam
      annotations:
        description: '{{`Node {{ $labels.node }} in cluster {{ $labels.installation }}/{{ $labels.cluster_id }} has CAPI taint node.cluster.x-k8s.io/uninitialized for too long`}}'
        runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/unexpected-taint-capi/
      expr: kube_node_spec_taint{key="node.cluster.x-k8s.io/uninitialized"} > 0
      for: 20m
      labels:
        area: kaas
        cancel_if_outside_working_hours: "true"
        severity: page
        team: {{ include "providerTeam" . }}
        topic: kubernetes
