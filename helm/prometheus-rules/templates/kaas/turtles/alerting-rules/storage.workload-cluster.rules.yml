apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  creationTimestamp: null
  labels:
    {{- include "labels.common" . | nindent 4 }}
{{- if not .Values.mimir.enabled }}
    cluster_type: "workload_cluster"
{{- end }}
  name: core.storage.workload-cluster.rules
  namespace: {{ .Values.namespace  }}
spec:
  groups:
  - name: core.storage.workload-cluster
    rules:
    - alert: DockerVolumeSpaceTooLow
      annotations:
        description: '{{`Docker volume {{ $labels.mountpoint}} on {{ $labels.instance }} does not have enough free space.`}}'
        opsrecipe: low-disk-space/#docker-volume
      expr: node_filesystem_free_bytes{cluster_type="workload_cluster", mountpoint=~"(/rootfs)?/var/lib/docker"} < (2 * 1024 * 1024 * 1024)
      for: 30m
      labels:
        area: kaas
        severity: page
        team: {{ include "providerTeam" . }}
        topic: storage
    - alert: EtcdVolumeSpaceTooLow
      annotations:
        description: '{{`Etcd volume {{ $labels.mountpoint}} on {{ $labels.instance }} does not have enough free space.`}}'
        opsrecipe: low-disk-space/#etcd-volume
      expr: 100 * node_filesystem_free_bytes{cluster_type="workload_cluster", mountpoint=~"(/rootfs)?/var/lib/etcd", provider!="eks"} / node_filesystem_size_bytes{cluster_type="workload_cluster", mountpoint=~"(/rootfs)?/var/lib/etcd", provider!="eks"} < 10
      for: 10m
      labels:
        area: kaas
        cancel_if_outside_working_hours: {{ include "workingHoursOnly" . }}
        severity: page
        team: {{ include "providerTeam" . }}
        topic: storage
    - alert: KubeletVolumeSpaceTooLow
      annotations:
        description: '{{`Kubelet volume /var/lib/kubelet on {{ $labels.node }} does not have enough free space.`}}'
        opsrecipe: low-disk-space/#kubelet-volume
      # In clusters where the node-problem-detector-app (https://github.com/giantswarm/node-problem-detector-app/) is installed, we don't want to get alerted if the node-problem-detector is already remediating the issue. 
      # When this happens, the problem_gauge metric has value 1, so we do a multiply join on that metric - 1 to get 0 when the metric is present and active, and keep the series values that are > 0. 
      # The right hand side of the or is necessary because we need to be alerted in clusters without the node-problem-detector.
      # Note that we add 1 to the disk free space so we still get alerted when the free bytes are 0.
      # We are also alerted if the free space is less than 2GB for 30 minutes.
      expr: (( node_filesystem_free_bytes{cluster_type="workload_cluster",mountpoint=~"(/rootfs)?/var/lib/kubelet"} +1 < (2 * 1024 * 1024 * 1024)) * on (node, cluster_type, cluster_id, installation, organization, pipeline, region, customer) (1 - problem_gauge{reason="KubeletDiskIsFull"}) or sum (node_filesystem_free_bytes{cluster_type="workload_cluster",mountpoint=~"(/rootfs)?/var/lib/kubelet"} +1 < (2 * 1024 * 1024 * 1024)) by (node, cluster_type, cluster_id, installation, organization, pipeline, region, customer)) > 0
      for: 60m
      labels:
        area: kaas
        severity: page
        team: {{ include "providerTeam" . }}
        topic: storage
    - alert: LogVolumeSpaceTooLow
      annotations:
        description: '{{`Log volume /var/log on {{ $labels.node }} does not have enough free space.`}}'
        opsrecipe: low-disk-space/#log-volume
      # See above comment for the KubeletVolumeSpaceTooLow alert regarding the node-problem-detector.
      # We are also alerted if the free space is less than 10% for 30 minutes.
      expr: (( 100 * (node_filesystem_free_bytes{cluster_type="workload_cluster", mountpoint=~"(/rootfs)?/var/log"} +1) / node_filesystem_size_bytes{cluster_type="workload_cluster", mountpoint=~"(/rootfs)?/var/log"} < 10) * on (node, cluster_type, cluster_id, installation, organization, pipeline, region, customer) (1 - problem_gauge{reason="VarLogDiskIsFull"}) or sum ((100 * node_filesystem_free_bytes{cluster_type="workload_cluster", mountpoint=~"(/rootfs)?/var/log"} +1)/ node_filesystem_size_bytes{cluster_type="workload_cluster", mountpoint=~"(/rootfs)?/var/log"} < 10) by (node, cluster_type, cluster_id, installation, organization, pipeline, region, customer)) > 0
      for: 60m
      labels:
        area: kaas
        severity: page
        team: {{ include "providerTeam" . }}
        topic: storage
    - alert: RootVolumeSpaceTooLow
      annotations:
        description: '{{`Root volume {{ $labels.mountpoint}} on {{ $labels.instance }} does not have enough free space.`}}'
        opsrecipe: low-disk-space/#root-volume
      expr: 100 * node_filesystem_free_bytes{cluster_type="workload_cluster", mountpoint=~"(/rootfs)?/"} / node_filesystem_size_bytes{cluster_type="workload_cluster", mountpoint=~"(/rootfs)?/"} < 10
      for: 10m
      labels:
        area: kaas
        severity: page
        team: {{ include "providerTeam" . }}
        topic: storage
