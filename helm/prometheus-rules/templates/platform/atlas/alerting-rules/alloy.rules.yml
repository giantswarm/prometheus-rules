# This files describe common alloy alerting rules
# For alerts regarding monitoring and logging agents, please go to the respective files (logging.rules.yml and monitoring.rules.yml).
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    {{- include "labels.common" . | nindent 4 }}
  name: alloy.rules
  namespace: {{ .Values.namespace }}
spec:
  groups:
    # List of alerts for on the state of the alloy components.
    # Alerts are coming from https://github.com/grafana/alloy/blob/ed52746567d2469a6a97a592ac5aec807646b327/operations/alloy-mixin/alerts/controller.libsonnet
    # We added the alert labels and added the missing labels from the aggregations.
    - name: alloy.controller
      rules:
        - alert: AlloySlowComponentEvaluations
          annotations:
            dashboard: bf9f456aad7108b2c808dbd9973e386f/alloy-controller
            description: '{{`Component evaluations are taking too long under job {{ $labels.job }}, component_path {{ $labels.component_path }}, component_id {{ $labels.component_id }}.`}}'
            opsrecipe: alloy/
            summary: Component evaluations are taking too long.
          expr: sum by (cluster_id, installation, provider, pipeline, namespace, job, component_path, component_id) (rate(alloy_component_evaluation_slow_seconds[10m])) > 0
          for: 15m
          labels:
            area: platform
            severity: notify
            team: atlas
            topic: observability
            cancel_if_outside_working_hours: "true"
            cancel_if_cluster_status_creating: "true"
            cancel_if_cluster_status_deleting: "true"
            cancel_if_cluster_status_updating: "true"
        - alert: AlloyUnhealthyComponents
          annotations:
            dashboard: bf9f456aad7108b2c808dbd9973e386f/alloy-controller
            description: '{{`Unhealthy components detected under job {{ $labels.job }}`}}'
            opsrecipe: alloy/
            summary: Unhealthy components detected.
          expr: sum by (cluster_id, installation, provider, pipeline, namespace, job) (alloy_component_controller_running_components{health_type!="healthy"}) > 0
          for: 15m
          labels:
            area: platform
            severity: page
            team: atlas
            topic: observability
            cancel_if_outside_working_hours: "true"
            cancel_if_cluster_status_creating: "true"
            cancel_if_cluster_status_deleting: "true"
            cancel_if_cluster_status_updating: "true"
    - name: alloy.rules
      rules:
        - alert: AlloyForPrometheusRulesDown
          annotations:
            description: 'Alloy sending PrometheusRules to Loki and Mimir ruler is down.'
            opsrecipe: prometheus-rules/
          expr: count(up{job="alloy-rules", namespace="monitoring"} == 0) by (cluster_id, installation, provider, pipeline) > 0
          for: 1h
          labels:
            area: platform
            cancel_if_cluster_status_creating: "true"
            cancel_if_cluster_status_deleting: "true"
            cancel_if_cluster_status_updating: "true"
            cancel_if_outside_working_hours: "true"
            severity: page
            team: atlas
            topic: observability
    - name: alloy.logs
      rules:
        # This alert lists the existing logging-agent pods (to extract the node label and inhibit if the node is not ready)
        # and join the pods with the not running containers
        - alert: LoggingAgentDown
          annotations:
            dashboard: 53c1ecddc3a1d5d4b8d6cd0c23676c31/alloy-logs-overview
            description: '{{`Scraping of all logging-agent pods to check if one failed every 30 minutes.`}}'
            opsrecipe: alloy/
          expr: |-
            kube_pod_info{pod=~"alloy-logs.*"}
            * on(cluster_id, pod)
              group_left ()
              up{job="alloy-logs", container="alloy"} == 0
          for: 30m
          labels:
            area: platform
            severity: page
            team: atlas
            topic: observability
            cancel_if_outside_working_hours: "true"
            cancel_if_cluster_status_creating: "true"
            cancel_if_cluster_status_deleting: "true"
            cancel_if_cluster_status_updating: "true"
            cancel_if_node_unschedulable: "true"
            cancel_if_node_not_ready: "true"
