{{- if not (or (eq .Values.managementCluster.provider.kind "vsphere") (eq .Values.managementCluster.provider.kind "cloud-director")) }}
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  creationTimestamp: null
  labels:
    {{- include "labels.common" . | nindent 4 }}
  name: fluentbit.rules
  namespace: {{ .Values.namespace  }}
spec:
  groups:
  - name: fluentbit
    rules:
    - alert: FluentbitTooManyErrors
      annotations:
        description: '{{`Fluentbit ({{ $labels.instance }}) is erroring.`}}'
        runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/fluentbit-too-many-erros/
        __dashboardUid__: fluentbit
        dashboardQueryParams: "orgId=2"
      # If we have some failures sending data, raise an alert
      expr: rate(fluentbit_output_retries_failed_total{namespace=~"kube-system|monitoring"}[10m]) > 0
      for: 20m
      labels:
        area: platform
        cancel_if_outside_working_hours: "true"
        severity: page
        team: atlas
        topic: observability
    - alert: FluentbitDropRatio
      annotations:
        description: '{{`Fluentbit ({{ $labels.instance }}) is dropping more than 1% records.`}}'
        runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/fluentbit-too-many-erros/
        __dashboardUid__: fluentbit
        dashboardQueryParams: "orgId=2"
      # Check the ratio of dropped records over the total number of records.
      expr: |-
        rate(
          fluentbit_output_dropped_records_total{namespace=~"kube-system|monitoring"}[10m])
          / (
            rate(fluentbit_output_proc_records_total{namespace=~"kube-system|monitoring"}[10m])
            + rate(fluentbit_output_dropped_records_total{namespace=~"kube-system|monitoring"}[10m])
          )
        > 0.01
      for: 20m
      labels:
        area: platform
        cancel_if_outside_working_hours: "true"
        severity: page
        team: atlas
        topic: observability
    - alert: FluentbitDown
      annotations:
        description: '{{`Fluentbit is down on node ({{ $labels.node }}).`}}'
        runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/fluentbit-down/
        __dashboardUid__: fluentbit
        dashboardQueryParams: "orgId=2"
      expr: sum(up{job="fluent-logshipping-app"}) by (job, cluster_id, installation, provider, pipeline, namespace, node) == 0
      for: 15m
      labels:
        area: platform
        cancel_if_outside_working_hours: "true"
        severity: page
        team: atlas
        topic: observability
    - alert: FluentbitDaemonSetNotSatisfied
      annotations:
        description: '{{`Daemonset {{ $labels.namespace}}/{{ $labels.daemonset }} is not satisfied.`}}'
        runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/daemonset-not-satisfied/
        __dashboardUid__: fluentbit
        dashboardQueryParams: "orgId=2"
      expr: kube_daemonset_status_number_unavailable{daemonset="fluent-logshipping-app"} > 0
      for: 1h
      labels:
        area: platform
        cancel_if_outside_working_hours: "true"
        severity: page
        team: atlas
        topic: observability
{{- end }}
