apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    {{- include "labels.common" . | nindent 4 }}
  name: grafana.rules
  namespace: {{ .Values.namespace }}
spec:
  groups:
  - name: grafana
    rules:
    - alert: GrafanaDown
      annotations:
        description: '{{`Grafana ({{ $labels.instance }}) is down.`}}'
        runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/grafana-down/
        __dashboardUid__: qRQXmRnik
        dashboardQueryParams: "orgId=2"
      expr: up{service="grafana", cluster_type="management_cluster"} == 0
      for: 1h
      labels:
        area: platform
        cancel_if_outside_working_hours: "true"
        severity: page
        team: atlas
        topic: observability
    - alert: GrafanaPostgresqlReplicationFailure
      annotations:
        description: '{{`grafana-postgresql replication is lagging for pod {{ $labels.pod }}.`}}'
        runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/grafana-down/
      expr: sum(cnpg_pg_replication_lag{namespace="monitoring", pod=~"grafana-postgresql.*"}) by (pod, cluster_id, installation, pipeline, provider) > 300
      for: 10m
      labels:
        area: platform
        cancel_if_outside_working_hours: "true"
        severity: page
        team: atlas
        topic: observability
    - alert: GrafanaPostgresqlArchivingFailure
      annotations:
        description: '{{`grafana-postgresql archiving failed for pod {{ $labels.pod }}.`}}'
        runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/grafana-down/
      expr: sum((cnpg_pg_stat_archiver_last_failed_time{namespace="monitoring", pod=~"grafana-postgresql.*"} - cnpg_pg_stat_archiver_last_archived_time{namespace="monitoring", pod=~"grafana-postgresql.*"})) by (pod, cluster_id, installation, pipeline, provider) > 1
      for: 5m
      labels:
        area: platform
        cancel_if_outside_working_hours: "true"
        severity: page
        team: atlas
        topic: observability
    - alert: GrafanaPostgresqlRecoveryTestFailed
      annotations:
        description: '{{`grafana-postgresql db automated recovery test failed.`}}'
        runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/grafana-down/
      # If we have a pod for grafana-postgresql-recovery-test postgresql cluster running for 1 hour, we can consider the recovery failed. This alert works because the test clusters are automatically deleted right after the tests are successful, and the grafana database is small so restore+tests never take that long.
      expr: sum(kube_pod_info{cluster_type="management_cluster", namespace="monitoring", pod=~"grafana-postgresql-recovery-test-[0-9]+"}) by (cluster_id, installation, pipeline, provider) >= 1
      for: 1h
      labels:
        area: platform
        cancel_if_outside_working_hours: "true"
        severity: page
        team: atlas
        topic: observability
