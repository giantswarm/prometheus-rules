apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    {{- include "labels.common" . | nindent 4 }}
  name: logging-pipeline.rules
  namespace: {{ .Values.namespace }}
spec:
  groups:
    - name: tracing-pipeline
      rules:
        # This alert will trigger if the failure rate of spans sent by the OTEL exporter exceeds a defined threshold (e.g., 10%).
        - alert: OTLPTraceForwardingErrors
          annotations:
            __dashboardUid__: 9b6d37c8603e19e8922133984faad93d
            dashboardQueryParams: "orgId=2"
            summary: Alloy OTLP exporter is failing to send spans.
            description: '{{`The Alloy OTLP exporter has failed to send {{ printf "%.1f" $value }}% of spans over the last 5 minutes.`}}'
            runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/tracing-pipeline/
          expr: |-
            (
              rate(otelcol_exporter_send_failed_spans_total[5m])
              /
              (
                rate(otelcol_exporter_send_failed_spans_total[5m])
                +
                rate(otelcol_exporter_sent_spans_total[5m])
              )
            ) * 100
            >= 10  # Trigger if failure rate exceeds 10%
          for: 1h
          labels:
            area: platform
            severity: page
            team: atlas
            topic: observability
            cancel_if_outside_working_hours: "true"
        # This alert triggers if the Alloy OTLP exporter fails to enqueue spans at a sustained rate exceeding 100 spans per second over 5 minutes, which could indicate upstream issues or resource constraints.
        - alert: OTLPExporterEnqueueFailures
          annotations:
            summary: Alloy OTLP exporter enqueue failures exceed 100 spans/second over 5 minutes
            description: '{{`The Alloy OTLP exporter has failed to enqueue more than 100 spans per second on average over the last 5 minutes, indicating potential upstream issues.`}}'
            runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/tracing-pipeline/
            __dashboardUid__: 9b6d37c8603e19e8922133984faad93d 
            dashboardQueryParams: "orgId=2"
          expr: rate(otelcol_exporter_enqueue_failed_spans_total[5m]) > 100
          for: 1h
          labels:
            area: platform
            severity: page
            team: atlas
            topic: observability
            cancel_if_outside_working_hours: "true"
