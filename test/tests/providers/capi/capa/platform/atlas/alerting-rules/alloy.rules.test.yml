---
rule_files:
  - alloy.rules.yml

tests:
  # Test AlloySlowComponentEvaluations
  - interval: 1m
    input_series:
      - series: 'alloy_component_evaluation_slow_seconds{cluster_id="golem", installation="golem", provider="capa", pipeline="testing", namespace="default", job="alloy-controller", component_id="comp1"}'
        values: "0+0x10 0+1x50 0x50"
    alert_rule_test:
      - alertname: AlloySlowComponentEvaluations
        eval_time: 10m
      - alertname: AlloySlowComponentEvaluations
        eval_time: 50m
        exp_alerts:
          - exp_labels:
              area: platform
              cancel_if_outside_working_hours: "true"
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
              cancel_if_cluster_status_updating: "true"
              cluster_id: golem
              installation: golem
              provider: capa
              pipeline: testing
              namespace: default
              job: alloy-controller
              component_id: comp1
              severity: notify
              team: atlas
              topic: observability
            exp_annotations:
              dashboardUid: bf9f456aad7108b2c808dbd9973e386f/alloy-controller?orgId=2
              description: "Component evaluations are taking too long under job alloy-controller, component_id comp1."
              runbook_url: "alloy/"
              summary: "Component evaluations are taking too long."
      - alertname: AlloySlowComponentEvaluations
        eval_time: 80m

  # Test AlloyUnhealthyComponents
  - interval: 1m
    input_series:
      - series: 'alloy_component_controller_running_components{health_type="unhealthy", cluster_id="golem", installation="golem", provider="capa", pipeline="testing", namespace="default", job="alloy-controller"}'
        values: "0+0x10 1+0x50 0x50"
    alert_rule_test:
      - alertname: AlloyUnhealthyComponents
        eval_time: 10m
      - alertname: AlloyUnhealthyComponents
        eval_time: 30m
        exp_alerts:
          - exp_labels:
              area: platform
              cancel_if_outside_working_hours: "true"
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
              cancel_if_cluster_status_updating: "true"
              cluster_id: golem
              installation: golem
              provider: capa
              pipeline: testing
              namespace: default
              job: alloy-controller
              severity: page
              team: atlas
              topic: observability
            exp_annotations:
              dashboardUid: bf9f456aad7108b2c808dbd9973e386f/alloy-controller?orgId=2
              description: "Unhealthy components detected under job alloy-controller"
              runbook_url: "alloy/"
              summary: "Unhealthy components detected."
      - alertname: AlloyUnhealthyComponents
        eval_time: 80m

  # Test AlloyForPrometheusRulesDown
  - interval: 1m
    input_series:
      # test with 1 pod: none, up, down
      - series: 'up{job="alloy-rules", cluster_type="management_cluster", cluster_id="golem", provider="capa", pipeline="testing", installation="golem", namespace="monitoring"}'
        values: "_x20 1+0x70 0+0x70"
    alert_rule_test:
      - alertname: AlloyForPrometheusRulesDown
        eval_time: 10m
      - alertname: AlloyForPrometheusRulesDown
        eval_time: 80m
      - alertname: AlloyForPrometheusRulesDown
        eval_time: 160m
        exp_alerts:
          - exp_labels:
              area: platform
              cancel_if_outside_working_hours: "true"
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
              cancel_if_cluster_status_updating: "true"
              cluster_id: golem
              installation: golem
              provider: capa
              pipeline: testing
              severity: page
              team: atlas
              topic: observability
            exp_annotations:
              description: "Alloy sending PrometheusRules to Loki and Mimir ruler is down."
              runbook_url: "prometheus-rules/"

  # Test LoggingAgentDown
  - interval: 1m
    input_series:
      # For the first 80min: test with 1 pod: none, up, down
      - series: 'up{container="alloy", cluster_id="golem", cluster_type="management_cluster", installation="golem", job="alloy-logs", pod="alloy-logs-1xxxx", provider="capa", pipeline="testing"}'
        values: "_x20 1+0x20 0+0x40"
      - series: kube_pod_info{cluster_id="golem", cluster_type="management_cluster", installation="golem", pod="alloy-logs-1xxxx", node="ip-10-0-5-1.eu-west-1.compute.internal", provider="capa", pipeline="testing"}
        values: "1x180"
      # From 80min: test with 2 pods: 1 up and 1 down, 2 up, 2 down.
      - series: 'up{container="alloy", cluster_id="golem", cluster_type="management_cluster", installation="golem", job="alloy-logs", pod="alloy-logs-2xxxx", provider="capa", pipeline="testing"}'
        values: "_x80 1+0x40 1+0x20 0+0x40"
      - series: kube_pod_info{cluster_id="golem", cluster_type="management_cluster", installation="golem", pod="alloy-logs-2xxxx", node="ip-10-0-5-2.eu-west-1.compute.internal", provider="capa", pipeline="testing"}
        values: "1x180"
      - series: 'up{container="alloy", cluster_type="management_cluster", cluster_id="golem", installation="golem", job="alloy-logs", pod="alloy-logs-3xxxx", provider="capa", pipeline="testing"}'
        values: "_x80 0+0x40 1+0x20 0+0x40"
      - series: kube_pod_info{cluster_id="golem", cluster_type="management_cluster", installation="golem", pod="alloy-logs-3xxxx", node="ip-10-0-5-3.eu-west-1.compute.internal", provider="capa", pipeline="testing"}
        values: "1x180"
    alert_rule_test:
      - alertname: LoggingAgentDown
        eval_time: 10m
      - alertname: LoggingAgentDown
        eval_time: 30m
      - alertname: LoggingAgentDown
        eval_time: 71m
        exp_alerts:
          - exp_labels:
              area: platform
              cancel_if_outside_working_hours: "true"
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
              cancel_if_cluster_status_updating: "true"
              cancel_if_node_unschedulable: "true"
              cancel_if_node_not_ready: "true"
              cluster_id: golem
              cluster_type: management_cluster
              installation: golem
              node: ip-10-0-5-1.eu-west-1.compute.internal
              pipeline: testing
              pod: alloy-logs-1xxxx
              provider: capa
              severity: page
              team: atlas
              topic: observability
            exp_annotations:
              dashboardUid: "53c1ecddc3a1d5d4b8d6cd0c23676c31/alloy-logs-overview?orgId=2"
              description: "Scraping of all logging-agent pods to check if one failed every 30 minutes."
              runbook_url: "alloy/"
      # Tests with 2 pods
      - alertname: LoggingAgentDown
        eval_time: 111m
        exp_alerts:
          - exp_labels:
              area: platform
              cancel_if_outside_working_hours: "true"
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
              cancel_if_cluster_status_updating: "true"
              cancel_if_node_unschedulable: "true"
              cancel_if_node_not_ready: "true"
              cluster_id: golem
              cluster_type: management_cluster
              installation: golem
              node: ip-10-0-5-3.eu-west-1.compute.internal
              pipeline: testing
              pod: alloy-logs-3xxxx
              provider: capa
              severity: page
              team: atlas
              topic: observability
            exp_annotations:
              dashboardUid: "53c1ecddc3a1d5d4b8d6cd0c23676c31/alloy-logs-overview?orgId=2"
              description: "Scraping of all logging-agent pods to check if one failed every 30 minutes."
              runbook_url: "alloy/"
      - alertname: LoggingAgentDown
        eval_time: 121m
      - alertname: LoggingAgentDown
        eval_time: 180m
        exp_alerts:
          - exp_labels:
              area: platform
              cancel_if_outside_working_hours: "true"
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
              cancel_if_cluster_status_updating: "true"
              cancel_if_node_unschedulable: "true"
              cancel_if_node_not_ready: "true"
              cluster_id: golem
              cluster_type: management_cluster
              installation: golem
              node: ip-10-0-5-2.eu-west-1.compute.internal
              pipeline: testing
              pod: alloy-logs-2xxxx
              provider: capa
              severity: page
              team: atlas
              topic: observability
            exp_annotations:
              dashboardUid: "53c1ecddc3a1d5d4b8d6cd0c23676c31/alloy-logs-overview?orgId=2"
              description: "Scraping of all logging-agent pods to check if one failed every 30 minutes."
              runbook_url: "alloy/"
          - exp_labels:
              area: platform
              cancel_if_outside_working_hours: "true"
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
              cancel_if_cluster_status_updating: "true"
              cancel_if_node_unschedulable: "true"
              cancel_if_node_not_ready: "true"
              cluster_id: golem
              cluster_type: management_cluster
              installation: golem
              node: ip-10-0-5-3.eu-west-1.compute.internal
              pipeline: testing
              pod: alloy-logs-3xxxx
              provider: capa
              severity: page
              team: atlas
              topic: observability
            exp_annotations:
              dashboardUid: "53c1ecddc3a1d5d4b8d6cd0c23676c31/alloy-logs-overview?orgId=2"
              description: "Scraping of all logging-agent pods to check if one failed every 30 minutes."
              runbook_url: "alloy/"

  # Test MonitoringAgentDown
  - interval: 1m
    input_series:
      - series: 'up{job="alloy-metrics", cluster_id="golem", installation="golem", provider="capa", pipeline="testing"}'
        values: "_x40 1+0x50 0+0x70"
      - series: 'capi_cluster_status_condition{type="ControlPlaneReady", status="True", name="golem", installation="golem", provider="capa", pipeline="testing"}'
        values: "1x150"
    alert_rule_test:
      - alertname: MonitoringAgentDown
        eval_time: 10m
      - alertname: InhibitionMonitoringAgentDown
        eval_time: 10m
        exp_alerts:
          - exp_labels:
              area: platform
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
              inhibit_monitoring_agent_down: "true"
              cluster_id: golem
              installation: golem
              provider: capa
              pipeline: testing
              severity: none
              team: atlas
              topic: observability
            exp_annotations:
              description: "Monitoring agent fails to send samples."
              runbook_url: "alloy/#monitoring-agent-down"
              dashboardUid: "promRW001/prometheus-remote-write?orgId=1"
              summary: "Monitoring agent fails to send samples to remote write endpoint."
      - alertname: MonitoringAgentDown
        eval_time: 30m
        exp_alerts:
          - exp_labels:
              area: platform
              cancel_if_cluster_has_no_workers: "true"
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
              inhibit_monitoring_agent_down: "true"
              cluster_id: golem
              installation: golem
              provider: capa
              pipeline: testing
              severity: page
              team: atlas
              topic: observability
            exp_annotations:
              description: "Monitoring agent fails to send samples."
              runbook_url: "alloy/#monitoring-agent-down"
              dashboardUid: "promRW001/prometheus-remote-write?orgId=1"
              summary: "Monitoring agent fails to send samples to remote write endpoint."
      - alertname: InhibitionMonitoringAgentDown
        eval_time: 30m
        exp_alerts:
          - exp_labels:
              area: platform
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
              inhibit_monitoring_agent_down: "true"
              cluster_id: golem
              installation: golem
              provider: capa
              pipeline: testing
              severity: none
              team: atlas
              topic: observability
            exp_annotations:
              description: "Monitoring agent fails to send samples."
              runbook_url: "alloy/#monitoring-agent-down"
              dashboardUid: "promRW001/prometheus-remote-write?orgId=1"
              summary: "Monitoring agent fails to send samples to remote write endpoint."
      - alertname: MonitoringAgentDown
        eval_time: 80m
      - alertname: InhibitionMonitoringAgentDown
        eval_time: 80m
      - alertname: MonitoringAgentDown
        eval_time: 140m
        exp_alerts:
          - exp_labels:
              area: platform
              cancel_if_cluster_has_no_workers: "true"
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
              inhibit_monitoring_agent_down: "true"
              cluster_id: golem
              installation: golem
              provider: capa
              pipeline: testing
              severity: page
              team: atlas
              topic: observability
            exp_annotations:
              description: "Monitoring agent fails to send samples."
              runbook_url: "alloy/#monitoring-agent-down"
              dashboardUid: "promRW001/prometheus-remote-write?orgId=1"
              summary: "Monitoring agent fails to send samples to remote write endpoint."
      - alertname: InhibitionMonitoringAgentDown
        eval_time: 140m
        exp_alerts:
          - exp_labels:
              area: platform
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
              inhibit_monitoring_agent_down: "true"
              cluster_id: golem
              installation: golem
              provider: capa
              pipeline: testing
              severity: none
              team: atlas
              topic: observability
            exp_annotations:
              description: "Monitoring agent fails to send samples."
              runbook_url: "alloy/#monitoring-agent-down"
              dashboardUid: "promRW001/prometheus-remote-write?orgId=1"
              summary: "Monitoring agent fails to send samples to remote write endpoint."

  # Test MonitoringAgentShardsNotSatisfied
  - interval: 1m
    input_series:
      - series: 'kube_statefulset_status_replicas{statefulset="alloy-metrics", cluster_id="golem", installation="golem", provider="capa", pipeline="testing"}'
        values: "3+0x10 3+0x90 3+0x50"
      - series: 'kube_statefulset_status_replicas_ready{statefulset="alloy-metrics", cluster_id="golem", installation="golem", provider="capa", pipeline="testing"}'
        values: "3+0x10 2+0x90 3+0x50"
    alert_rule_test:
      - alertname: MonitoringAgentShardsNotSatisfied
        eval_time: 10m
      - alertname: MonitoringAgentShardsNotSatisfied
        eval_time: 30m
      - alertname: InhibitionMonitoringAgentShardsNotSatisfied
        eval_time: 30m
        exp_alerts:
          - exp_labels:
              area: platform
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
              cluster_id: golem
              installation: golem
              provider: capa
              pipeline: testing
              severity: none
              statefulset: alloy-metrics
              team: atlas
              topic: observability
              inhibit_monitoring_agent_down: "true"
            exp_annotations:
              description: "At least one of the monitoring agent shard is missing."
              summary: "Monitoring agent is missing shards."
              runbook_url: "alloy/#monitoring-agent-down"
      - alertname: MonitoringAgentShardsNotSatisfied
        eval_time: 60m
        exp_alerts:
          - exp_labels:
              area: platform
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
              cancel_if_outside_working_hours: "true"
              cluster_id: golem
              installation: golem
              provider: capa
              pipeline: testing
              severity: page
              statefulset: alloy-metrics
              team: atlas
              topic: observability
              inhibit_monitoring_agent_down: "true"
            exp_annotations:
              description: "At least one of the monitoring agent shard is missing."
              summary: "Monitoring agent is missing shards."
              runbook_url: "alloy/#monitoring-agent-down"
      - alertname: InhibitionMonitoringAgentShardsNotSatisfied
        eval_time: 60m
        exp_alerts:
          - exp_labels:
              area: platform
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
              cluster_id: golem
              installation: golem
              provider: capa
              pipeline: testing
              severity: none
              statefulset: alloy-metrics
              team: atlas
              topic: observability
              inhibit_monitoring_agent_down: "true"
            exp_annotations:
              description: "At least one of the monitoring agent shard is missing."
              summary: "Monitoring agent is missing shards."
              runbook_url: "alloy/#monitoring-agent-down"
      - alertname: MonitoringAgentShardsNotSatisfied
        eval_time: 130m
      - alertname: InhibitionMonitoringAgentShardsNotSatisfied
        eval_time: 130m
