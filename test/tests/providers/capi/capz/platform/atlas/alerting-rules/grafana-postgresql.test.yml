---
rule_files:
  - grafana-postgresql.rules.yml

tests:
  - interval: 1m
    input_series:
      - series: 'up{cluster_id="golem", cluster_type="management_cluster", container="postgres", customer="giantswarm", endpoint="metrics", installation="golem", instance="100.64.35.156:9187", job="monitoring/grafana-postgresql-extra", namespace="monitoring", organization="giantswarm", pipeline="testing", pod="grafana-postgresql-1", provider="capa", region="eu-west-2", service_priority="highest"}'
        values: "1+0x20 0+0x20 1+0x20 _x20 1+0x40"  # healthy for 20 minutes, unhealthy for 20 minutes, healthy for 20 minutes, no data for 20 minutes, healthy for 40 minutes
      - series: 'up{cluster_id="golem", cluster_type="management_cluster", container="postgres", customer="giantswarm", endpoint="metrics", installation="golem", instance="100.64.35.156:9187", job="monitoring/grafana-postgresql-extra", namespace="monitoring", organization="giantswarm", pipeline="testing", pod="grafana-postgresql-2", provider="capa", region="eu-west-2", service_priority="highest"}'
        values: "1+0x40 0+0x20 _x40 1+0x20"  # healthy for 40 minutes, unhealthy for 20 minutes, no data for 40 minutes, healthy for 20 minutes
    alert_rule_test:
      - alertname: GrafanaPostgresqlDown
        eval_time: 15m  # should be OK after 15 minutes
        exp_alerts: []
      - alertname: GrafanaPostgresqlDown
        eval_time: 25m  # After 25 minutes, should fire an alert
        exp_alerts:
          - exp_labels:
              area: platform
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
              cancel_if_cluster_status_updating: "true"
              cancel_if_outside_working_hours: "true"
              severity: page
              team: atlas
              topic: observability
            exp_annotations:
              description: The grafana-postgresql cluster has one or more unhealthy instances.
              runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/grafana-down/
      - alertname: GrafanaPostgresqlDown
        eval_time: 45m  # After 45 minutes, should fire an alert
        exp_alerts:
          - exp_labels:
              area: platform
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
              cancel_if_cluster_status_updating: "true"
              cancel_if_outside_working_hours: "true"
              severity: page
              team: atlas
              topic: observability
            exp_annotations:
              description: The grafana-postgresql cluster has one or more unhealthy instances.
              runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/grafana-down/
      - alertname: GrafanaPostgresqlDown
        eval_time: 65m  # After 65 minutes, should fire an alert
        exp_alerts:
          - exp_labels:
              area: platform
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
              cancel_if_cluster_status_updating: "true"
              cancel_if_outside_working_hours: "true"
              severity: page
              team: atlas
              topic: observability
            exp_annotations:
              description: The grafana-postgresql cluster has one or more unhealthy instances.
              runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/grafana-down/
      - alertname: GrafanaPostgresqlDown
        eval_time: 90m  # should be OK after 90 minutes
        exp_alerts: []
