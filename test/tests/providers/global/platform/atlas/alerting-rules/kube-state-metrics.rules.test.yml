---
rule_files:
- kube-state-metrics.rules.yml

tests:
  # KubeStateMetricsDown tests
  # Tests to be run:
  # - no "up" metrics
  # - "up" metrics with servicemonitor discovery (ports 8080 and 8081)
  #   - "up" metric for port 8080 is OK, but port 8081 is set to 0
  #   - "up" metric for port 8080 is set to 0, but port 8080 is OK
  # - "up" metrics with label discovery (random port)
  # - "up" is ok, but we don't have enough metrics
  - name: "KSMDown with servicemonitor discovery"
    interval: 1m
    input_series:
      # Tests for servicemonitor discovery
      # - 00:00 Start with no metrics
      # - 00:30 Both ports up and enough metrics
      # - 01:00 Port 8080 goes down
      # - 01:30 All is up again
      # - 02:00 Port 8081 goes down
      # - 02:30 all is up again
      # - 03:00 we don't have enough metrics
      # - 03:30 all is up again
      - series: 'up{job="kube-state-metrics", cluster_id="golem", cluster_type="management_cluster", container="kube-state-metrics", customer="giantswarm", endpoint="http", installation="golem", instance="192.0.2.10:8080", namespace="kube-system", node="ip-10-0-1-1.eu-west-1.compute.internal", organization="giantswarm", pipeline="testing", pod="prometheus-operator-app-kube-state-metrics-d7f4ff68d-72vzx", provider="capa", region="eu-west-1", service="prometheus-operator-app-kube-state-metrics", service_priority="highest"}'
        values: "_x30 1x30 0x30 1x30 1x30 1x30 1x30 1x30"
      - series: 'up{job="kube-state-metrics", cluster_id="golem", cluster_type="management_cluster", container="kube-state-metrics", customer="giantswarm", endpoint="metrics", installation="golem", instance="192.0.2.10:8081", namespace="kube-system", node="ip-10-0-1-1.eu-west-1.compute.internal", organization="giantswarm", pipeline="testing", pod="prometheus-operator-app-kube-state-metrics-d7f4ff68d-72vzx", provider="capa", region="eu-west-1", service="prometheus-operator-app-kube-state-metrics", service_priority="highest"}'
        values: "_x30 1x30 1x30 1x30 0x30 1x30 1x30 1x30"
      - series: 'testmetric2{job="kube-state-metrics"}'
        values: "0x1000"
      - series: 'testmetric3{job="kube-state-metrics"}'
        values: "0x1000"
      - series: 'testmetric4{job="kube-state-metrics"}'
        values: "0x1000"
      - series: 'testmetric5{job="kube-state-metrics"}'
        values: "0x1000"
      - series: 'testmetric6{job="kube-state-metrics"}'
        values: "0x1000"
      - series: 'testmetric7{job="kube-state-metrics"}'
        values: "0x1000"
      - series: 'testmetric8{job="kube-state-metrics"}'
        values: "0x1000"
      - series: 'testmetric9{job="kube-state-metrics"}'
        values: "_x30 1x30 1x30 1x30 1x30 1x30 _x30 1x30"
    alert_rule_test:
      # - 00:00 Start with no metrics
      - alertname: KubeStateMetricsDown
        eval_time: 25m
        exp_alerts:
          - exp_labels:
              area: "platform"
              cancel_if_cluster_control_plane_unhealthy: "true"
              cancel_if_kubelet_down: "true"
              cancel_if_outside_working_hours: "false"
              inhibit_kube_state_metrics_down: "true"
              cancel_if_monitoring_agent_down: "true"
              severity: "page"
              team: "atlas"
              topic: "observability"
              cluster_id: "golem"
              installation: "golem"
              provider: "capa"
              pipeline: "testing"
            exp_annotations:
              description: "KubeStateMetrics () is down."
              runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/kube-state-metrics-down/
      # - 00:30 Both ports up and enough metrics
      - alertname: KubeStateMetricsDown
        eval_time: 55m
      # - 01:00 Port 8080 goes down
      - alertname: KubeStateMetricsDown
        eval_time: 85m
        exp_alerts:
          - exp_labels:
              area: "platform"
              cancel_if_cluster_control_plane_unhealthy: "true"
              cancel_if_kubelet_down: "true"
              cancel_if_outside_working_hours: "false"
              inhibit_kube_state_metrics_down: "true"
              cancel_if_monitoring_agent_down: "true"
              severity: "page"
              team: "atlas"
              topic: "observability"
              cluster_id: "golem"
              installation: "golem"
              provider: "capa"
              pipeline: "testing"
            exp_annotations:
              description: "KubeStateMetrics () is down."
              runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/kube-state-metrics-down/
      # - 01:30 All is up again
      - alertname: KubeStateMetricsDown
        eval_time: 115m
      # - 02:00 Port 8081 goes down
      - alertname: KubeStateMetricsDown
        eval_time: 145m
      # - 02:30 all is up again
      - alertname: KubeStateMetricsDown
        eval_time: 175m
      # - 03:00 we don't have enough metrics
      - alertname: KubeStateMetricsDown
        eval_time: 205m
        exp_alerts:
          - exp_labels:
              area: "platform"
              cancel_if_cluster_control_plane_unhealthy: "true"
              cancel_if_kubelet_down: "true"
              cancel_if_outside_working_hours: "false"
              inhibit_kube_state_metrics_down: "true"
              cancel_if_monitoring_agent_down: "true"
              severity: "page"
              team: "atlas"
              topic: "observability"
              cluster_id: "golem"
              installation: "golem"
              provider: "capa"
              pipeline: "testing"
            exp_annotations:
              description: "KubeStateMetrics () is down."
              runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/kube-state-metrics-down/
      # - 03:30 all is up again
      - alertname: KubeStateMetricsDown
        eval_time: 235m


  # Tests for label-discovery targets
  - name: "KSMDown with label discovery"
    interval: 1m
    input_series:
      # - 00:00 Start with no metrics
      # - 00:30 all goes up
      # - 01:00 up goes down
      # - 01:30 All is up again
      - series: 'up{job="kube-state-metrics", cluster_id="golem", cluster_type="workload_cluster", customer="giantswarm", installation="golem", instance="10.0.2.4:10301", namespace="kube-system", node="ip-10-1-0-3.eu-west-1.compute.internal", organization="giantswarm", pod="kube-state-metrics-v2-3-0-67b5fdc5d4-78mhf", provider="capa", service_priority="highest"}'
        values: "_x30 1x30 0x30 1x30"
      - series: 'testmetric2{job="kube-state-metrics"}'
        values: "0x1000"
      - series: 'testmetric3{job="kube-state-metrics"}'
        values: "0x1000"
      - series: 'testmetric4{job="kube-state-metrics"}'
        values: "0x1000"
      - series: 'testmetric5{job="kube-state-metrics"}'
        values: "0x1000"
      - series: 'testmetric6{job="kube-state-metrics"}'
        values: "0x1000"
      - series: 'testmetric7{job="kube-state-metrics"}'
        values: "0x1000"
      - series: 'testmetric8{job="kube-state-metrics"}'
        values: "0x1000"
      - series: 'testmetric9{job="kube-state-metrics"}'
        values: "0x1000"
      - series: 'testmetric10{job="kube-state-metrics"}'
        values: "0x1000"
    alert_rule_test:
      # - 00:00 Start with no metrics
      - alertname: KubeStateMetricsDown
        eval_time: 25m
        exp_alerts:
          - exp_labels:
              area: "platform"
              cancel_if_cluster_control_plane_unhealthy: "true"
              cancel_if_kubelet_down: "true"
              cancel_if_outside_working_hours: "false"
              inhibit_kube_state_metrics_down: "true"
              cancel_if_monitoring_agent_down: "true"
              severity: "page"
              team: "atlas"
              topic: "observability"
              cluster_id: "golem"
              installation: "golem"
              provider: "capa"
              pipeline: "testing"
            exp_annotations:
              description: "KubeStateMetrics () is down."
              runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/kube-state-metrics-down/
      # - 00:30 all goes up
      - alertname: KubeStateMetricsDown
        eval_time: 55m
      # - 01:00 up goes down
      - alertname: KubeStateMetricsDown
        eval_time: 85m
        exp_alerts:
          - exp_labels:
              area: "platform"
              cancel_if_cluster_control_plane_unhealthy: "true"
              cancel_if_kubelet_down: "true"
              cancel_if_outside_working_hours: "false"
              inhibit_kube_state_metrics_down: "true"
              cancel_if_monitoring_agent_down: "true"
              severity: "page"
              team: "atlas"
              topic: "observability"
              cluster_id: "golem"
              installation: "golem"
              provider: "capa"
              pipeline: "testing"
            exp_annotations:
              description: "KubeStateMetrics () is down."
              runbook_url: https://intranet.giantswarm.io/docs/support-and-ops/ops-recipes/kube-state-metrics-down/
      # - 01:30 All is up again
      - alertname: KubeStateMetricsDown
        eval_time: 115m
