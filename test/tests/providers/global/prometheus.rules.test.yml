---
rule_files:
  - prometheus.rules.yml

# Setting evaluation interval to 1h
# to make it faster on long test duration.
evaluation_interval: 1h

tests:
  # Test PrometheusAvailabilityRatio
  - interval: 1m
    input_series:
      # This prometheus is up foreve - generates no alert
      - series: 'kube_pod_status_ready{app="kube-state-metrics", condition="true", container="kube-state-metrics", namespace="install-prometheus", pod="prometheus-install-0"}'
        values: "1+0x600"
      # This prometheus starts at h+2, and takes 15min to get ready - generates no alert
      - series: 'kube_pod_status_ready{app="kube-state-metrics", condition="true", container="kube-state-metrics", namespace="wcok-prometheus", pod="prometheus-wcok-0"}'
        values: "_x120 0+0x15 1+0x600"
      # This promteheus is down - generates alerts
      - series: 'kube_pod_status_ready{app="kube-state-metrics", condition="true", container="kube-state-metrics", namespace="wcbad-prometheus", pod="prometheus-wcbad-0"}'
        values: "0+0x600"
    alert_rule_test:
      - alertname: PrometheusAvailabilityRatio
        eval_time: 135m
        exp_alerts:
          - exp_labels:
              area: empowerment
              severity: page
              team: atlas
              topic: observability
              cancel_if_any_apiserver_down: "true"
              cancel_if_cluster_has_no_workers: "true"
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
              cancel_if_cluster_status_updating: "true"
              cancel_if_outside_working_hours: "true"
              pod: "prometheus-wcbad-0"
            exp_annotations:
              description: "Prometheus prometheus-wcbad-0 has availability ratio of 0.00 (min 0.8) over the last 10 hours."
              opsrecipe: "prometheus-resource-limit-reached/"
              dashboard: "promavailability/prometheus-availability"
      - alertname: PrometheusAvailabilityRatio
        eval_time: 4h
        exp_alerts:
          - exp_labels:
              area: empowerment
              severity: page
              team: atlas
              topic: observability
              cancel_if_any_apiserver_down: "true"
              cancel_if_cluster_has_no_workers: "true"
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
              cancel_if_cluster_status_updating: "true"
              cancel_if_outside_working_hours: "true"
              pod: "prometheus-wcbad-0"
            exp_annotations:
              description: "Prometheus prometheus-wcbad-0 has availability ratio of 0.00 (min 0.8) over the last 10 hours."
              opsrecipe: "prometheus-resource-limit-reached/"
              dashboard: "promavailability/prometheus-availability"
      - alertname: PrometheusAvailabilityRatio
        eval_time: 15h
        exp_alerts:
          - exp_labels:
              area: empowerment
              severity: page
              team: atlas
              topic: observability
              cancel_if_any_apiserver_down: "true"
              cancel_if_cluster_has_no_workers: "true"
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
              cancel_if_cluster_status_updating: "true"
              cancel_if_outside_working_hours: "true"
              pod: "prometheus-wcbad-0"
            exp_annotations:
              description: "Prometheus prometheus-wcbad-0 has availability ratio of 0.00 (min 0.8) over the last 10 hours."
              opsrecipe: "prometheus-resource-limit-reached/"
              dashboard: "promavailability/prometheus-availability"
  # Test PrometheusJobScrapingFailure and PrometheusCriticalJobScrapingFailure
  - interval: 1h
    input_series:
      - series: 'up{app="kubernetes",installation="gauss",cluster_id="gauss",job="gauss-prometheus/kubernetes-apiserver-gauss/0"}'
        values: "1+0x240"
      # critcal target up for 5d and down for 5d
      - series: 'up{app="kube-controller-manager",installation="gauss",cluster_id="gauss",job="gauss-prometheus/kubernetes-controller-manager-gauss/0"}'
        values: "1+0x120 0+0x120"
      - series: 'up{app="kube-scheduler",installation="gauss",cluster_id="gauss",job="gauss-prometheus/kubernetes-scheduler-gauss/0"}'
        values: "1+0x240"
      - series: 'up{app="kubelet",installation="gauss",cluster_id="gauss",job="gauss-prometheus/kubernetes-kubelet-gauss/0"}'
        values: "1+0x240"
      - series: 'up{app="node-exporter",installation="gauss",cluster_id="gauss",job="gauss-prometheus/node-exporter-gauss/0"}'
        values: "1+0x240"
      - series: 'up{app="kube-state-metrics",installation="gauss",cluster_id="gauss",job="gauss-prometheus/kube-state-metrics-gauss/0"}'
        values: "1+0x240"
      # Add bastion host test to ensure we do not page
      - series: 'up{app="node-exporter",installation="gauss",cluster_id="gauss",job="gauss-prometheus/bastions/0"}'
        values: "1+0x240"
      # non-critcal target up for 5d and down for 5d
      - series: 'up{app="app-exporter",installation="gauss",cluster_id="gauss",job="gauss-prometheus/app-exporter-gauss/0"}'
        values: "1+0x120 0+0x120"
    alert_rule_test:
      - alertname: PrometheusCriticalJobScrapingFailure
        eval_time: 30m
      - alertname: PrometheusJobScrapingFailure
        eval_time: 1d
      - alertname: PrometheusCriticalJobScrapingFailure
        eval_time: 4d
      # This alert fires for both critical and non-critical targets
      - alertname: PrometheusJobScrapingFailure
        eval_time: 7d
        exp_alerts:
          - exp_labels:
              area: empowerment
              severity: none
              team: atlas
              topic: observability
              cancel_if_outside_working_hours: "true"
              cluster_id: "gauss"
              installation: "gauss"
              job: "gauss-prometheus/kubernetes-controller-manager-gauss/0"
            exp_annotations:
              opsrecipe: "prometheus-job-scraping-failure/"
              summary: "Prometheus fails to scrape all targets in a job."
              description: "Prometheus gauss/gauss has failed to scrape all targets in gauss-prometheus/kubernetes-controller-manager-gauss/0 job."
          - exp_labels:
              area: empowerment
              severity: none
              team: atlas
              topic: observability
              cancel_if_outside_working_hours: "true"
              cluster_id: "gauss"
              installation: "gauss"
              job: "gauss-prometheus/app-exporter-gauss/0"
            exp_annotations:
              opsrecipe: "prometheus-job-scraping-failure/"
              summary: "Prometheus fails to scrape all targets in a job."
              description: "Prometheus gauss/gauss has failed to scrape all targets in gauss-prometheus/app-exporter-gauss/0 job."

      # This fires only for critical target down.
      - alertname: PrometheusCriticalJobScrapingFailure
        eval_time: 9d
        exp_alerts:
          - exp_labels:
              area: empowerment
              severity: page
              team: atlas
              topic: observability
              app: "kube-controller-manager"
              cluster_id: "gauss"
              installation: "gauss"
              job: "gauss-prometheus/kubernetes-controller-manager-gauss/0"
              cancel_if_outside_working_hours: "true"
              cancel_if_cluster_is_not_running_prometheus_agent: "true"
              cancel_if_cluster_status_creating: "true"
              cancel_if_cluster_status_deleting: "true"
            exp_annotations:
              opsrecipe: "prometheus-job-scraping-failure/"
              summary: "Prometheus fails to scrape all targets in a job."
              description: "Prometheus gauss/gauss has failed to scrape all targets in gauss-prometheus/kubernetes-controller-manager-gauss/0 job."
